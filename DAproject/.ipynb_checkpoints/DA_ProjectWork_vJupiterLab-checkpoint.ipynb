{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Project\n",
    "*Participants: Ilia Rozanovskii, Katarzyna Rongiers*\n",
    "\n",
    "**For better user experience, it is recomended to run Viola-view**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Data analysis is a part of data science, the process of cleaning, changing, and processing raw data, and extracting actionable, relevant information that helps make informed decisions.\n",
    "\n",
    "The aim of this work is to make regression analysis of selected dataset. The selection of dataset was the first task. Due to small experience in data analysis, the selected dataset accords to some conditions. At first, is has narrow set of independed variables (or attributes), it increases the clearence of correlation between variables. Secondly, the dataset contains plenty of instances comparing to other available datasets. Larger number of instances gives better model accuracy and therefor is better choice. \n",
    "\n",
    "The dataset analized in this work contains minimal health records of 110,204 admissions (primary cohort), 19,051 admissions (study cohort), and 137 admissions (validation cohort) of patients who had sepsis. During the work the set of  logistic regression models was generated and one of the models is selected as final model. Additionally, simple user interface to model prediction is generated.\n",
    "\n",
    "This work should be considered only as student work with datasets. As long as the dataset and the models concerns to medical field, especially a matter of life and death, we declare, that any result of current work cannot and should not be used as ground for any  decisions related to health, medical, social and others fields.\n",
    "\n",
    "The used dataset could be found here: \n",
    " [Sepsis data sets](https://archive.ics.uci.edu/ml/datasets/Sepsis+survival+minimal+clinical+records).\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset analysis\n",
    "\n",
    "Analysis in the work is made using ```python``` programming language and a set of available libraries. \n",
    "The first step of the dataset analysis is the basic descriptive statistics and searching of correlation between depended and independed variables. \n",
    "\n",
    "The selected dataset contain three different part. \n",
    "All three sets are going to be taken into account when getting the model. Therefore each data subset loaded by program and has its unique name assign to it. Before processing of data and model analisis, the data sets are cleared -- all instances , that contains non-number values (NaN) are droped out. Additionally, the depended variable placed into dedicated place to uniform the structure of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets\n",
    "#%pip install voila\n",
    "#%pip install voila-gridstack\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import pandas.util.testing as tm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown as md\n",
    "import itertools\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input data\n",
    "## data filename\n",
    "datafilename1 = 'sepsis_survival_primary.csv'\n",
    "datafilename2 = 'sepsis_survival_study.csv'\n",
    "datafilename3 = 'sepsis_survival_validation.csv'\n",
    "\n",
    "## depended Variable column name\n",
    "dependVar = 'hospital_outcome_1alive_0dead'\n",
    "## exclude columns from analyze (text, urls, etc. )\n",
    "excludeColumns = []\n",
    "## minimum correlation coeff to assume as a key variable\n",
    "minimumCorrCoef = 0.01\n",
    "threshold = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read CSV file, autodetect delimeters, skip spaces in names\n",
    "df1 = pd.read_csv(datafilename1, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df2 = pd.read_csv(datafilename2, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df3 = pd.read_csv(datafilename3, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "dfs = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    ## exclude columns\n",
    "    df.drop(excludeColumns, axis ='columns', inplace = True)\n",
    "    ## and drop  all NaN\n",
    "    df.dropna(inplace=True)\n",
    "    ## place depended var into pos 0\n",
    "    poped = df.pop(dependVar)\n",
    "    df.insert(0, poped.name, poped)\n",
    "        \n",
    "## independed variable columns names  \n",
    "independVarList = list(df.columns.values)\n",
    "independVarList.remove(dependVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset analysis begin with basic introduction to the variables. There are numeric as well as categorical variables. First group constist of ```age_years``` and ```episode_number```, next group has ```hospital_outcome_1alive_0dead``` and ```sex_0male_1female```. Where ```sex_0male_1female``` is categorical variable: 0 reperesent male gender and 1 represent female gender. Where ```hospital_outcome_1alive_0dead``` is __the dependent variable__: 0 respresents illness outcome resolving in death of the patient and 1 concluding the alive state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowHideableOutput():\n",
    "    def __init__(self, outputGenerator, description=\"output\"):\n",
    "        self.outputGenerator = outputGenerator\n",
    "        self.description = description\n",
    "        layout = widgets.Layout(width='auto', height='40px') #set width and height\n",
    "        self.wdg_button   = widgets.ToggleButton(\n",
    "                    value=False,\n",
    "                    description='Show ' + self.description,\n",
    "                    disabled=False,\n",
    "                    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                    tooltip='Press to show/hide output information',\n",
    "                    icon='check', # (FontAwesome names without the `fa-` prefix)\n",
    "                    layout = layout\n",
    "                )\n",
    "        self.wdg_output  = widgets.Output(layout={'border': '3px solid green'})\n",
    "        display(self.wdg_button, self.wdg_output)\n",
    "        self.wdg_button.observe(self._onchange_wdg_button, names='value')\n",
    "\n",
    "    def _onchange_wdg_button(self, change):\n",
    "        if (change['new']) :\n",
    "            with self.wdg_output:\n",
    "                display('Output is shown, press button above to hide it.')\n",
    "                self.outputGenerator()\n",
    "            self.wdg_button.description = 'Hide ' + self.description\n",
    "        else:\n",
    "            self.wdg_button.description = 'Show ' + self.description\n",
    "            self.wdg_output.clear_output()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, both data sets summary tables are visulised to have a brief look on the brief statictics of the values. Seaborn library is used for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7ff180303a4e5cb4bbffba4f643b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show basic statistic', icon='check', layout=Layout(height='40px', width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fee81c79cad4675bfb27e7ed0d347ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_stats():\n",
    "    display(md(\"\"\"Dataset ```df1``` (primary cohort)  statistic:\"\"\"))\n",
    "    display(df1.describe())\n",
    "    display(md(\"\"\"Dataset ```df2``` (study cohort)  statistic:\"\"\"))\n",
    "    display(df2.describe())\n",
    "    display(md(\"\"\"Dataset ```df3``` (validation cohort)  statistic:\"\"\"))\n",
    "    display(df3.describe())\n",
    "    \n",
    "    \n",
    "var = ShowHideableOutput(out_show_stats, \"basic statistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reviewRawData:\n",
    "    #all plots for data set to be reviewed in\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.pairPlot()\n",
    "        self.HeatmapCorr()\n",
    "        self.scatterPlot()\n",
    "        self.histogramPlot()\n",
    "        \n",
    "    def scatterPlot(self):\n",
    "        allVars=df.columns\n",
    "        nxdr2x = widgets.Dropdown(options = allVars, value = allVars[1], \n",
    "                            description = 'X value', option = 'X var')\n",
    "        nxdr2y = widgets.Dropdown(options = allVars, value = allVars[1], \n",
    "                            description = 'X value', option = 'X var')\n",
    "\n",
    "        def plot_scatterplot(x = 'age_years', y = 'hospital_outcome_1alive_0dead'):    \n",
    "            sns.scatterplot(data = self.df, x = x, y = y)\n",
    "\n",
    "        out2 = widgets.interact(plot_scatterplot, x=nxdr2x, y = nxdr2y)\n",
    "        ui = widgets.HBox([nxdr2x,nxdr2y])\n",
    "        \n",
    "    def pairPlot(self):\n",
    "        display(md(\"\"\"Pairplot of variables of dataset\"\"\"))\n",
    "        sns.pairplot(self.df)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def HeatmapCorr(self): \n",
    "        sns.set(rc = {'figure.figsize':(15,8)})\n",
    "        sns.set_theme(style=\"white\")\n",
    "        corr = self.df.corr()\n",
    "        # Generate a mask for the upper triangle\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "        # Custom colormap\n",
    "        cmap = sns.diverging_palette(275, 150, s=90, l=50, n=9, as_cmap=True)\n",
    "        sns.heatmap(corr, mask=mask, cmap=cmap,  linewidths=0.3, cbar_kws={\"shrink\":0.5})\n",
    "        \n",
    "    def histogramPlot(self):\n",
    "        allVars=df.columns\n",
    "        nxdr = widgets.Dropdown(options = allVars, value = allVars[1], \n",
    "                            description = 'X value', option = 'X var')\n",
    "\n",
    "        nBinsdr = widgets.Dropdown(options=[2,5,10,15,20,40], value=15, \n",
    "                            description = 'Bins number', option = 'Bin value')\n",
    "\n",
    "        def plot_histogram(x = 'age_years', nBins = 15, PlotKDE = False):    \n",
    "            sns.histplot(data = self.df[x] , bins = nBins, kde = PlotKDE)\n",
    "\n",
    "        out = widgets.interact(plot_histogram, nBins = nBinsdr,PlotKDE = False,x=nxdr)\n",
    "        ui = widgets.HBox([nxdr,nBinsdr]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then data from sets can be visualised for better understanding. The values in the sets are compared using different plots. This provides an even better understanding of the correlation between the variables. Both three data set can be selected for this basic visualisation analysis. Following the data set choice, three charts display the correlation between variables like correlation heatmap, scatterplot and histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba11e31c302949749184e6e9a58db79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show statistical graphs', icon='check', layout=Layout(height='40px', wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92b45eac60d495cad0b34569b230594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_statistic_graphs():\n",
    "    ##dfChoice = np.array({'df1':'df 1','df2':'df 2','df3':'df 3'})\n",
    "    dfChoice = np.asarray(['df1','df2','df3'])\n",
    "    ndf = widgets.Dropdown(options = dfChoice, value = dfChoice[0], \n",
    "                        description = 'dfChoice', option = 'dfChoice')\n",
    "\n",
    "    def plot_review(x = ndf):\n",
    "        #plotting according to chosen data set\n",
    "        if x == 'df1':\n",
    "            z = reviewRawData(df1)\n",
    "        elif x == 'df2':\n",
    "            z = reviewRawData(df2)\n",
    "        elif x == 'df3':\n",
    "            z = reviewRawData(df3)\n",
    "\n",
    "    out = widgets.interact(plot_review, x = ndf) \n",
    "    ui = widgets.HBox([ndf]) \n",
    "        \n",
    "var = ShowHideableOutput(out_show_statistic_graphs, \"statistical graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "There are a lot of different types of models are developed. Each of them is suitable for specific situation, used data types, target of modeling and other factors. The model choice is importante stage of data analysis, because the selected modeling method imposes some restrictions on the accuracy, validity and actuality of the result model.\n",
    "\n",
    "For the problem in this project, logistic regression was chosen. The logistic regression usually used in case the predicting value is a categorical variable. In current case predicting value is dependent variable, which has two possible (binary) values: 0 and 1. In fact the prediction output of model is not the value 0 either 1, but the probability that value is 1. This is the reason why in table of models present ```passprob``` column. Finaly, the two possible values expected as output result of model. With different probability used as threshold, the same model gives different output results. \n",
    "\n",
    "Depending on situation and dataset under analysis, different approach for criteries could be selected. In this project the question is the survival of people is predicted. Therefore the model should be selected the way to minimize so called \"false negative\" cases. False negative prediction means the model predicts output \"0\" (death), but in fact there was output \"1\" (alive). Decreasing of false negative prediction increase false positive cases and decreases \"effectiveness\" of model. But, as was mentioned before, the correct model selection depends on the meaning of data under analysis.\n",
    "\n",
    "The models in this chapter are generated using ```df1``` (primary cohort) as training data for model and ```df2``` (study cohort) as testing data for model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, dfTrain, dfTest):\n",
    "        self.dfTrain = dfTrain.copy()\n",
    "        self.dfTest = dfTest.copy()\n",
    "        self.models = []\n",
    "        self.modresults = []\n",
    "        self.predictVars = []\n",
    "        self.workingModel = None\n",
    "        ### make models for all variables and combinations\n",
    "        self.allResults = pd.DataFrame(columns=['vars', 'passprob', 'res', 'model', 'BA', 'TP', 'FN', 'TN', 'FP'])\n",
    "        self.CalculateModels()\n",
    "        self.TestModels()\n",
    "        \n",
    "    def CalculateModels(self):\n",
    "        keyVars = self.GetKeyVariables()\n",
    "        self.dependVar = keyVars['key'].iloc[0]\n",
    "        ### All vars into list.\n",
    "        self.predictVars = keyVars['key'].iloc[1:].to_list()    ## .iloc[1:NvarsCount+1].to_list()\n",
    "        ### make models for all variables, sequently adding one by one\n",
    "        for n,indvar in enumerate(self.predictVars):\n",
    "            indvars = self.predictVars[:n+1]\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain)\n",
    "            res = model.fit(disp=False)\n",
    "            self.models.append(model)\n",
    "            self.modresults.append(res)\n",
    "\n",
    "\n",
    "    def GetKeyVariables(self):\n",
    "        parCorr = pd.DataFrame(self.dfTrain.corr() )\n",
    "        n = len(parCorr.columns)\n",
    "        keyVars = pd.DataFrame(columns=['key', 'val'])\n",
    "        ## depended variable moved to index 0\n",
    "        i = 0\n",
    "        for j in range( n):\n",
    "            if j >= i:\n",
    "                keyVars = keyVars.append({'key':parCorr.columns[j],'val':parCorr.iloc[i, j]}, ignore_index=True)\n",
    "        ## sort key vars by value\n",
    "        ##### keyVars.pop(df.columns[0])\n",
    "        keyVars.sort_values(by='val', key=abs, ascending=False, inplace=True)\n",
    "        return keyVars\n",
    "\n",
    "    \n",
    "    def get_BA(self, crossdf):\n",
    "        crossdf.index = crossdf.index.map(str)\n",
    "        crossdf.columns = crossdf.columns.map(str)\n",
    "        try: TN = crossdf.loc['0','0']\n",
    "        except: TN = 0\n",
    "        try: FN = crossdf.loc['0','1']\n",
    "        except: FN = 0\n",
    "        try: FP = crossdf.loc['1','0']\n",
    "        except: FP = 0\n",
    "        try: TP = crossdf.loc['1','1']\n",
    "        except: TP = 0\n",
    "        ###print('tn=', TN, 'fn=', FN, 'fp=', FP, 'tp=', TP)\n",
    "        # sensitivity = (TP)/(TP+FN)\n",
    "        # specificity = (TN)/(TN+FP)\n",
    "        # precision = (TP)/(TP+FP)\n",
    "        try: sensitivity = TP/(TP + FN)\n",
    "        except: sensitivity = np.NaN\n",
    "        try: specificity = TN/(TN + FP)\n",
    "        except: specificity = np.NaN\n",
    "        try: precision = TP/(TP + FP)\n",
    "        except: precision = np.NaN\n",
    "        BA = (sensitivity + specificity)/2\n",
    "        return dict(zip(['BA', 'sensitivity', 'specificity', 'precision', 'TN', 'FN', 'TP', 'FP'], [BA, sensitivity, specificity, precision, TN, FN, TP, FP]))\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def TestModels(self):\n",
    "        ### calculate BA for all threashholds...\n",
    "        passProbabilities = np.linspace(0,1,int(1/0.05)+1)\n",
    "\n",
    "        ## Generate all possible combinations of variables\n",
    "        variableList = sum([list(map(list, itertools.combinations(self.predictVars, i))) for i in range(len(self.predictVars) + 1)], [])\n",
    "        variableList = list(filter(None, variableList))\n",
    "\n",
    "        for n,indvars in enumerate(variableList):\n",
    "            ## progress # display(indvars)\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain )\n",
    "            fitresult = model.fit(disp=False)\n",
    "            for prob in passProbabilities:\n",
    "                inSample = pd.DataFrame({'probability':fitresult.predict(self.dfTest[indvars])}) \n",
    "                inSample['Model prediction'] = (inSample['probability'] >= prob).astype(int) ## 0 or 1 values based on probabilities\n",
    "                confMatrix = pd.crosstab(inSample['Model prediction'], self.dfTest[self.dependVar], dropna=False)\n",
    "                ba = self.get_BA(confMatrix)\n",
    "                ### add all info to one dataframe\n",
    "                ## TODO: memory consumption?\n",
    "                self.allResults = self.allResults.append({'vars':indvars, \n",
    "                                   'passprob':prob, \n",
    "                                   'res':fitresult, \n",
    "                                   'model':model,\n",
    "                                   'Rsqrd':fitresult.prsquared, **(ba)},\n",
    "                                 ignore_index=True)        \n",
    "\n",
    "        \n",
    "    def ShowResultsTable(self):\n",
    "        def _ui_show_result_table(sortcol1,sortcol2, sortorder1, sortorder2):\n",
    "            print(\"Selected columns and order: \", sortcol1,sortcol2, sortorder1, sortorder2)\n",
    "            allResults = self.allResults.reindex(\n",
    "                            index = self.dfBA.sort_values(by=[sortcol1,sortcol2], #['TP', 'BA'],#\n",
    "                                        ascending=[sortorder1,sortorder2]).index,\n",
    "                            copy=True)\n",
    "            pd.set_option(\"display.max_rows\", 400)\n",
    "            pd.set_option(\"display.max_columns\", 15)\n",
    "            pd.set_option(\"display.max_colwidth\", 2000)\n",
    "            display(allResults.loc[:, ~allResults.columns.isin(['res', 'model'])])\n",
    "            \n",
    "        sortableColumns = [item for item in list(self.allResults.columns) \n",
    "                   if item not in list(['vars', 'res', 'model'])] \n",
    "        self.dfBA = self.allResults.loc[:, sortableColumns].astype('float64').round(decimals=1)\n",
    "        sort1col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='FN',\n",
    "            description='Sort by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort2col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='Rsqrd',\n",
    "            description='and by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort1order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=True,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "        sort2order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=False,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "\n",
    "        sort1ui = widgets.HBox([sort1col,sort1order])\n",
    "        sort2ui = widgets.HBox([sort2col,sort2order])\n",
    "        resultui = widgets.interactive_output(_ui_show_result_table,\n",
    "                            {'sortcol1':sort1col,'sortcol2':sort2col, \n",
    "                             'sortorder1':sort1order,'sortorder2':sort2order})\n",
    "        display(sort1ui,sort2ui,resultui)\n",
    "        \n",
    "    def setWorkingModel(self, modelNumber):\n",
    "        if (modelNumber in self.allResults.index.values):\n",
    "            self.workingModel = modelNumber\n",
    "\n",
    "        \n",
    "    def getModelPrediction(self, dfInput, modelNumber=None):\n",
    "        if (modelNumber == None):\n",
    "            modelNumber = self.workingModel\n",
    "        if (modelNumber in self.allResults.index.values):\n",
    "            modelresult = self.allResults.iloc[modelNumber].res\n",
    "            return modelresult.predict(dfInput)\n",
    "        return []\n",
    "\n",
    "    def ShowModelInfo(self, modelNumber=None):\n",
    "        if (modelNumber == None):\n",
    "            modelNumber = self.workingModel\n",
    "        if (modelNumber in self.allResults.index.values):\n",
    "            modelresult = self.allResults.iloc[modelNumber].res\n",
    "            ## Print results\n",
    "            print(\"*\" * 80)\n",
    "            print(\"*\" * 20, f\"      Analyze results for model {modelNumber}     \",\"*\" * 20)\n",
    "            print(\"*\" * 80)\n",
    "            print(modelresult.summary() )\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Logistic regression models\n",
    "## the biggest dataset df1 as train daataset\n",
    "## the df2 as test dataset\n",
    "logreg1 = LogisticRegression(df1, df2)  ## df1-big as train\n",
    "logreg1.setWorkingModel(141)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f142fa02e3944dbb2fca69599b1461a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show models table', icon='check', layout=Layout(height='40px', width='a…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7063c2f144f946149e937ce8ca3037a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_models_table():\n",
    "    display(md(\"\"\"Key variables table:\"\"\"))\n",
    "    display(logreg1.GetKeyVariables())\n",
    "    display(md(\"\"\"Models comparison table:\"\"\"))\n",
    "    logreg1.ShowResultsTable()\n",
    "    \n",
    "var = ShowHideableOutput(out_show_models_table, \"models table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650c09fb09354b5c960b971e09aaefe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show model info', icon='check', layout=Layout(height='40px', width='aut…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37424bc218644bea688e1201f50f35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_models_info():\n",
    "    display(md(\"\"\"Selected model parameters:\"\"\"))\n",
    "    logreg1.ShowModelInfo()\n",
    "    \n",
    "var = ShowHideableOutput(out_show_models_info, \"model info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "As was mentioned above, different datasets require different approach to choosing the best one. On current dataset the best model was choosen based on such parameters as zero false negative cases and after that maximum of pseudo R-squared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "According to this factors, the model № ```141``` (see models table above) is selected as the working model.\n",
       "Based on the model, now user can input patient data and have predicted outcome for the illness. Form below accept all independent variables, next they are passed to chosen outcome prediction model. Information from the form is gathered in table. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(f\"\"\"According to this factors, the model № ```{logreg1.workingModel}``` (see models table above) is selected as the working model.\n",
    "Based on the model, now user can input patient data and have predicted outcome for the illness. Form below accept all independent variables, next they are passed to chosen outcome prediction model. Information from the form is gathered in table. \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomePredictionUI: \n",
    "    def __init__(self, logReg, independentVars):\n",
    "        self.ageMin = 20\n",
    "        self.ageMax = 100+1\n",
    "        self.episodesMin = 1\n",
    "        self.episodesMax = 5\n",
    "        \n",
    "        self.independentVars = independentVars.copy()\n",
    "        self.logReg = logReg\n",
    "        # self.formdf = pd.DataFrame(columns= [*self.independentVars, 'Result probability'])\n",
    "        self.formdf = self.logReg.dfTrain.drop(self.logReg.dfTrain.index)\n",
    "        self.i,self.j = 4,4\n",
    "        self.grid = widgets.GridspecLayout(self.i,self.j)\n",
    "        ### self.dfval = df[self.independentVars]\n",
    "        self.widgetsCreate()\n",
    "\n",
    "    def create_expanded_button(self,description, button_style):\n",
    "        return widgets.Button(description=description, button_style=button_style,\n",
    "                          layout=widgets.Layout(height='auto', width='auto'))\n",
    "\n",
    "    def widgetsCreate(self):\n",
    "        #BUTTONS\n",
    "        self.btn_Send = self.grid[2, 0] = self.create_expanded_button('Results'.format(0, 0), 'warning')\n",
    "        self.btn_Clear = self.grid[2, 1] = self.create_expanded_button('Clear'.format(0, 0), 'warning')\n",
    "        #self.btn_Results = self.grid[2, 2] = self.create_expanded_button('Get results'.format(0, 0), 'warning')\n",
    "        #Fields to select\n",
    "        self.btn_sex = self.grid[0,0] = widgets.Dropdown(description='Sex', options =['Female','Male'])\n",
    "        self.btn_age = self.grid[0,1] = widgets.Dropdown(description='Age', options =range(self.ageMin,self.ageMax))\n",
    "        self.btn_episodes = self.grid[0,2] = widgets.Dropdown(description='Episodes number', \n",
    "                                                              options =range(self.episodesMin,self.episodesMax))\n",
    "        \n",
    "        for j in range(2):\n",
    "            self.grid[2,j].on_click(self.on_btn_click)\n",
    "        #display the grid and table\n",
    "        self.out_table = widgets.Output()\n",
    "        display(md(f\"\"\"Working model: {self.logReg.workingModel}.\"\"\"))\n",
    "        display(self.grid, self.out_table)\n",
    "\n",
    "    def addToDF(self):\n",
    "        #self.formdf = self.logReg.dfTrain.drop(self.logReg.dfTrain.index)\n",
    "       \n",
    "        self.formdf = self.formdf.append(pd.DataFrame([[self.btn_age.value,self.btn_sex.value, \n",
    "                                           self.btn_episodes.value]], columns = self.independentVars),\n",
    "                                         ignore_index=True)\n",
    "        self.convertDF()\n",
    "        self.update_results()\n",
    "       \n",
    "    def convertDF(self):\n",
    "        #for user convinence - select gender name\n",
    "        #later converting before prdictions\n",
    "        \n",
    "        for i in range(0,len(self.formdf['sex_0male_1female'])):\n",
    "            self.formdf['sex_0male_1female'] =self.formdf['sex_0male_1female'].replace(['Male'],0)\n",
    "            self.formdf['sex_0male_1female'] =self.formdf['sex_0male_1female'].replace(['Female'],1)\n",
    "        resProbs = self.logReg.getModelPrediction(self.formdf)\n",
    "        self.formdf['Result probability'] = resProbs\n",
    "        self.formdf['Result: alive'] = resProbs > self.logReg.allResults.iloc[self.logReg.workingModel].passprob\n",
    "        self.update_results()\n",
    "             \n",
    "    def clear(self):\n",
    "        self.formdf = self.logReg.dfTrain.drop(self.logReg.dfTrain.index)\n",
    "        self.update_results()\n",
    "\n",
    "    def on_btn_click(self, btn):\n",
    "        if btn.description == 'Results':\n",
    "            self.addToDF()\n",
    "\n",
    "        elif btn.description == 'Clear':\n",
    "            self.clear()\n",
    "    \n",
    "    def update_results(self):\n",
    "        self.out_table.clear_output(wait=True)\n",
    "        formdf = self.formdf.copy()\n",
    "        formdf.pop(dependVar)\n",
    "        with self.out_table:\n",
    "            display(formdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form below allows the user to input values and have it evaluated further. Results prediction works upon the model prediction selected previously.\n",
    "The outcome of the evaluated values inserted in the form are the prediction of alive state of the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Working model: 141."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98510f41374c4d9cb24c7da2363a872c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Button(button_style='warning', description='Results', layout=Layout(grid_area='widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d829517b394802b19fd44110ab1136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var = OutcomePredictionUI(logreg1, [\"age_years\", \"sex_0male_1female\", \"episode_number\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second model\n",
    "\n",
    "In this paragraph the second model is tried to generate. In this case as training data the smallest dataset ```df3``` is used, and the same dataset ```df2``` is used as testing data. From models table below, it is hard to use the same principles as it was made for previous case. Additionally, have been noticed that the correlation coefficient of key variables  is totaly different comparing to previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate models for other datasets\n",
    "## df3 is smalest dataset now used as _train_\n",
    "## the same df2 used as test\n",
    "## is any difference comparing to first set?\n",
    "logreg3 = LogisticRegression(df3, df2)  ## df3-small as train\n",
    "logreg3.setWorkingModel(73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bea9acde544ad5b14b3c629fc0fab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show second model information', icon='check', layout=Layout(height='40p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc1dd5fd81e41e3817c080be38c5de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_model_2():\n",
    "    def out_show_models_table_2():\n",
    "        display(md(\"\"\"Key variables table:\"\"\"))\n",
    "        display(logreg3.GetKeyVariables())\n",
    "        display(md(\"\"\"Models for ```df3``` as train data comparison table:\"\"\"))\n",
    "        logreg3.ShowResultsTable()\n",
    "    def out_show_models_info_2():\n",
    "        display(md(\"\"\"Selected model parameters:\"\"\"))\n",
    "        logreg3.ShowModelInfo()\n",
    "    def out_show_prediction_2():\n",
    "        var = OutcomePredictionUI(logreg3, [\"age_years\", \"sex_0male_1female\", \"episode_number\"] )\n",
    "    \n",
    "    display(md(\"\"\"The key variables and correlation coefficient, models table\"\"\"))\n",
    "    var = ShowHideableOutput(out_show_models_table_2, \"models table 2\")\n",
    "    display(md(\"\"\"Selected model information\"\"\"))\n",
    "    var = ShowHideableOutput(out_show_models_info_2, \"model info 2\")    \n",
    "    var = OutcomePredictionUI(logreg3, [\"age_years\", \"sex_0male_1female\", \"episode_number\"] )\n",
    "    \n",
    "var = ShowHideableOutput(out_show_model_2, \"second model information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The results of dataset analysis is the logistic regression model what could be used for prediction. The process of model choosing is importante and difficult and the results integrally depends on this choice.   The structure of the analysis included many widgets with a user-friendly view. The results form gives the user the possibility to input information and make prediction straight away.  The overall analysis was executed as intended. When it comes to illness data set analysis and distinguishing between alive and dead state, as stated at the beginning, this particular evaluation cannot be taken as a valid outcome resulting in any health decisions.\n",
    "During this work was shown that the data analysis and model selection approach is data-depended and target-depended, and therefore could not be made fully automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
