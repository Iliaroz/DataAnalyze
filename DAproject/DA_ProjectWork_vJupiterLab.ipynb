{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Project\n",
    "*Participants: Ilia Rozanovskii, Katarzyna Rongiers*\n",
    "\n",
    "**For better user experience, it is recomended to run Viola-view**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Data analysis is a part of data science, the process of cleaning, changing, and processing raw data, and extracting actionable, relevant information that helps make informed decisions.\n",
    "\n",
    "The aim of this work is to make regression analysis of selected dataset. The selection of dataset was the first task. Due to small experience in data analysis, the selected dataset accords to some conditions. At first, is has narrow set of independed variables (or attributes), it increases the clearence of correlation between variables. Secondly, the dataset contains plenty of instances comparing to other available datasets. Larger number of instances gives better model accuracy and therefor is better choice. \n",
    "\n",
    "The dataset analized in this work contains minimal health records of 110,204 admissions (primary cohort), 19,051 admissions (study cohort), and 137 admissions (validation cohort) of patients who had sepsis. During the work the set of  logistic regression models was generated and one of the models is selected as final model. Additionally, simple user interface to model prediction is generated.\n",
    "\n",
    "This work should be considered only as student work with datasets. As long as the dataset and the models concerns to medical field, especially a matter of life and death, we declare, that any result of current work cannot and should not be used as ground for any  decisions related to health, medical, social and others fields.\n",
    "\n",
    "The used dataset could be found here: \n",
    " [Sepsis data sets](https://archive.ics.uci.edu/ml/datasets/Sepsis+survival+minimal+clinical+records).\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset analysis\n",
    "\n",
    "Analysis in the work is made using ```python``` programming language and a set of available libraries. \n",
    "The first step of the dataset analysis is the basic descriptive statistics and searching of correlation between depended and independed variables. \n",
    "\n",
    "The selected dataset contain three different part. \n",
    "All three sets are going to be taken into account when getting the model. Therefore each data subset loaded by program and has its unique name assign to it. Before processing of data and model analisis, the data sets are cleared -- all instances , that contains non-number values (NaN) are droped out. Additionally, the depended variable placed into dedicated place to uniform the structure of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets\n",
    "#%pip install voila\n",
    "#%pip install voila-gridstack\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import pandas.util.testing as tm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Markdown as md\n",
    "import itertools\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input data\n",
    "## data filename\n",
    "datafilename1 = 'sepsis_survival_primary.csv'\n",
    "datafilename2 = 'sepsis_survival_study.csv'\n",
    "datafilename3 = 'sepsis_survival_validation.csv'\n",
    "\n",
    "## depended Variable column name\n",
    "dependVar = 'hospital_outcome_1alive_0dead'\n",
    "## exclude columns from analyze (text, urls, etc. )\n",
    "excludeColumns = []\n",
    "## minimum correlation coeff to assume as a key variable\n",
    "minimumCorrCoef = 0.01\n",
    "threshold = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read CSV file, autodetect delimeters, skip spaces in names\n",
    "df1 = pd.read_csv(datafilename1, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df2 = pd.read_csv(datafilename2, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df3 = pd.read_csv(datafilename3, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "dfs = [df1, df2, df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    ## exclude columns\n",
    "    df.drop(excludeColumns, axis ='columns', inplace = True)\n",
    "    ## and drop  all NaN\n",
    "    df.dropna(inplace=True)\n",
    "    ## place depended var into pos 0\n",
    "    poped = df.pop(dependVar)\n",
    "    df.insert(0, poped.name, poped)\n",
    "        \n",
    "## independed variable columns names  \n",
    "independVarList = list(df.columns.values)\n",
    "independVarList.remove(dependVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowHideableOutput():\n",
    "    def __init__(self, outputGenerator, description=\"output\"):\n",
    "        self.outputGenerator = outputGenerator\n",
    "        self.description = description\n",
    "        layout = widgets.Layout(width='auto', height='40px') #set width and height\n",
    "        self.wdg_button   = widgets.ToggleButton(\n",
    "                    value=False,\n",
    "                    description='Show ' + self.description,\n",
    "                    disabled=False,\n",
    "                    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                    tooltip='Press to show/hide output information',\n",
    "                    icon='check', # (FontAwesome names without the `fa-` prefix)\n",
    "                    layout = layout\n",
    "                )\n",
    "        self.wdg_output  = widgets.Output(layout={'border': '3px solid green'})\n",
    "        display(self.wdg_button, self.wdg_output)\n",
    "        self.wdg_button.observe(self._onchange_wdg_button, names='value')\n",
    "\n",
    "    def _onchange_wdg_button(self, change):\n",
    "        if (change['new']) :\n",
    "            with self.wdg_output:\n",
    "                display('Output is shown, press button above to hide it.')\n",
    "                self.outputGenerator()\n",
    "            self.wdg_button.description = 'Hide ' + self.description\n",
    "        else:\n",
    "            self.wdg_button.description = 'Show ' + self.description\n",
    "            self.wdg_output.clear_output()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda8fa06711b420988049705d36c0728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show basic statistic', icon='check', layout=Layout(height='40px', widthâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11e28b9332648418c2f241f84b6cfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_stats():\n",
    "    display(md(\"\"\"Dataset ```df1``` (primary cohort)  statistic:\"\"\"))\n",
    "    display(df1.describe())\n",
    "    display(md(\"\"\"Dataset ```df2``` (study cohort)  statistic:\"\"\"))\n",
    "    display(df2.describe())\n",
    "    display(md(\"\"\"Dataset ```df3``` (validation cohort)  statistic:\"\"\"))\n",
    "    display(df3.describe())\n",
    "    \n",
    "    \n",
    "var = ShowHideableOutput(out_show_stats, \"basic statistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reviewRawData:\n",
    "    #all plots for data set to be reviewed in\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.HeatmapCorr()\n",
    "        #self.scatterPlot()\n",
    "        self.histogramPlot()\n",
    "        \n",
    "    def scatterPlot(self):\n",
    "        allVars=df.columns\n",
    "        nxdr2x = widgets.Dropdown(options = allVars, value = allVars[1], \n",
    "                            description = 'X value', option = 'X var')\n",
    "        nxdr2y = widgets.Dropdown(options = allVars, value = allVars[1], \n",
    "                            description = 'X value', option = 'X var')\n",
    "\n",
    "        def plot_scatterplot(x = 'age_years', y = 'hospital_outcome_1alive_0dead'):    \n",
    "            sns.scatterplot(data = self.df, x = x, y = y)\n",
    "\n",
    "        out2 = widgets.interact(plot_scatterplot, x=nxdr2x, y = nxdr2y)\n",
    "        ui = widgets.HBox([nxdr2x,nxdr2y])\n",
    "        \n",
    "    def HeatmapCorr(self): \n",
    "        sns.set(rc = {'figure.figsize':(15,8)})\n",
    "        sns.set_theme(style=\"white\")\n",
    "        corr = self.df.corr()\n",
    "        # Generate a mask for the upper triangle\n",
    "        mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "        # Custom colormap\n",
    "        cmap = sns.diverging_palette(275, 150, s=90, l=50, n=9, as_cmap=True)\n",
    "        sns.heatmap(corr, mask=mask, cmap=cmap,  linewidths=0.3, cbar_kws={\"shrink\":0.5})\n",
    "        \n",
    "    def histogramPlot(self):\n",
    "        allVars=df.columns\n",
    "        nxdr = widgets.Dropdown(options = allVars, value = allVars[1], \n",
    "                            description = 'X value', option = 'X var')\n",
    "\n",
    "        nBinsdr = widgets.Dropdown(options=[2,5,10,15,20,40], value=15, \n",
    "                            description = 'Bins number', option = 'Bin value')\n",
    "\n",
    "        def plot_histogram(x = 'age_years', nBins = 15, PlotKDE = False):    \n",
    "            sns.histplot(data = self.df[x] , bins = nBins, kde = PlotKDE)\n",
    "\n",
    "        out = widgets.interact(plot_histogram, nBins = nBinsdr,PlotKDE = False,x=nxdr)\n",
    "        ui = widgets.HBox([nxdr,nBinsdr]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then data from both three sets can be visualise for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00dc783c7c054baaacb6ed6106daf313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show statistical graphs', icon='check', layout=Layout(height='40px', wiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5abe8a69b7455ab0aa3c85d041b34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_statistic_graphs():\n",
    "    ##dfChoice = np.array({'df1':'df 1','df2':'df 2','df3':'df 3'})\n",
    "    dfChoice = np.asarray(['df1','df2','df3'])\n",
    "    ndf = widgets.Dropdown(options = dfChoice, value = dfChoice[0], \n",
    "                        description = 'dfChoice', option = 'dfChoice')\n",
    "\n",
    "    def plot_review(x = ndf):\n",
    "        #plotting according to chosen data set\n",
    "        if x == 'df1':\n",
    "            z = reviewRawData(df1)\n",
    "        elif x == 'df2':\n",
    "            z = reviewRawData(df2)\n",
    "        elif x == 'df3':\n",
    "            z = reviewRawData(df3)\n",
    "\n",
    "    out = widgets.interact(plot_review, x = ndf) \n",
    "    ui = widgets.HBox([ndf]) \n",
    "        \n",
    "var = ShowHideableOutput(out_show_statistic_graphs, \"statistical graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "There are a lot of different types of models are developed. Each of them is suitable for specific situation, used data types, target of modeling and other factors. The model choice is importante stage of data analysis, because the selected modeling method imposes some restrictions on the accuracy, validity and actuality of the result model.\n",
    "\n",
    "For the problem in this project, logistic regression was chosen. The logistic regression usually used in case the predicting value is a categorical variable. In current case predicting value is dependent variable, which has two possible (binary) values: 0 and 1. In fact the prediction output of model is not the value 0 either 1, but the probability that value is 1. This is the reason why in table of models present ```passprob``` column. Finaly, the two possible values expected as output result of model. With different probability used as threshold, the model gives different output results. \n",
    "\n",
    "Depending on situation and dataset under analysis, different approach for criteries could be selected. In this project the question is the survival of people is predicted. Therefore the model should be selected the way to minimize so called \"false negative\" cases. False negative prediction means the model predicts output \"0\" (death), but \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, dfTrain, dfTest):\n",
    "        self.dfTrain = dfTrain.copy()\n",
    "        self.dfTest = dfTest.copy()\n",
    "        self.models = []\n",
    "        self.modresults = []\n",
    "        self.predictVars = []\n",
    "        ### make models for all variables and combinations\n",
    "        self.allResults = pd.DataFrame(columns=['vars', 'passprob', 'res', 'model', 'BA', 'TP', 'FN', 'TN', 'FP'])\n",
    "        self.CalculateModels()\n",
    "        self.TestModels()\n",
    "        \n",
    "    def CalculateModels(self):\n",
    "        keyVars = self.GetKeyVariables(self.dfTrain)\n",
    "        self.dependVar = keyVars['key'].iloc[0]\n",
    "        ### All vars into list.\n",
    "        self.predictVars = keyVars['key'].iloc[1:].to_list()    ## .iloc[1:NvarsCount+1].to_list()\n",
    "        ### make models for all variables, sequently adding one by one\n",
    "        for n,indvar in enumerate(self.predictVars):\n",
    "            indvars = self.predictVars[:n+1]\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain)\n",
    "            res = model.fit(disp=False)\n",
    "            self.models.append(model)\n",
    "            self.modresults.append(res)\n",
    "\n",
    "\n",
    "    def GetKeyVariables(self, df):\n",
    "        parCorr = pd.DataFrame(df.corr() )\n",
    "        n = len(parCorr.columns)\n",
    "        keyVars = pd.DataFrame(columns=['key', 'val'])\n",
    "        ## depended variable moved to index 0\n",
    "        i = 0\n",
    "        for j in range( n):\n",
    "            if j >= i:\n",
    "                keyVars = keyVars.append({'key':parCorr.columns[j],'val':parCorr.iloc[i, j]}, ignore_index=True)\n",
    "        ## sort key vars by value\n",
    "        ##### keyVars.pop(df.columns[0])\n",
    "        keyVars.sort_values(by='val', key=abs, ascending=False, inplace=True)\n",
    "        return keyVars\n",
    "\n",
    "    \n",
    "    def get_BA(self, crossdf):\n",
    "        crossdf.index = crossdf.index.map(str)\n",
    "        crossdf.columns = crossdf.columns.map(str)\n",
    "        try: TN = crossdf.loc['0','0']\n",
    "        except: TN = 0\n",
    "        try: FN = crossdf.loc['0','1']\n",
    "        except: FN = 0\n",
    "        try: FP = crossdf.loc['1','0']\n",
    "        except: FP = 0\n",
    "        try: TP = crossdf.loc['1','1']\n",
    "        except: TP = 0\n",
    "        ###print('tn=', TN, 'fn=', FN, 'fp=', FP, 'tp=', TP)\n",
    "        # sensitivity = (TP)/(TP+FN)\n",
    "        # specificity = (TN)/(TN+FP)\n",
    "        # precision = (TP)/(TP+FP)\n",
    "        try: sensitivity = TP/(TP + FN)\n",
    "        except: sensitivity = np.NaN\n",
    "        try: specificity = TN/(TN + FP)\n",
    "        except: specificity = np.NaN\n",
    "        try: precision = TP/(TP + FP)\n",
    "        except: precision = np.NaN\n",
    "        BA = (sensitivity + specificity)/2\n",
    "        return dict(zip(['BA', 'sensitivity', 'specificity', 'precision', 'TN', 'FN', 'TP', 'FP'], [BA, sensitivity, specificity, precision, TN, FN, TP, FP]))\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def TestModels(self):\n",
    "        ### calculate BA for all threashholds...\n",
    "        passProbabilities = np.linspace(0,1,int(1/0.05)+1)\n",
    "\n",
    "        ## Generate all possible combinations of variables\n",
    "        variableList = sum([list(map(list, itertools.combinations(self.predictVars, i))) for i in range(len(self.predictVars) + 1)], [])\n",
    "        variableList = list(filter(None, variableList))\n",
    "\n",
    "        for n,indvars in enumerate(variableList):\n",
    "            ## progress # display(indvars)\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain )\n",
    "            fitresult = model.fit(disp=False)\n",
    "            for prob in passProbabilities:\n",
    "                inSample = pd.DataFrame({'probability':fitresult.predict(self.dfTest[indvars])}) \n",
    "                inSample['Model prediction'] = (inSample['probability'] >= prob).astype(int) ## 0 or 1 values based on probabilities\n",
    "                confMatrix = pd.crosstab(inSample['Model prediction'], self.dfTest[self.dependVar], dropna=False)\n",
    "                ba = self.get_BA(confMatrix)\n",
    "                ### add all info to one dataframe\n",
    "                ## TODO: memory consumption?\n",
    "                self.allResults = self.allResults.append({'vars':indvars, \n",
    "                                   'passprob':prob, \n",
    "                                   'res':fitresult, \n",
    "                                   'model':model,\n",
    "                                   'Rsqrd':fitresult.prsquared, **(ba)},\n",
    "                                 ignore_index=True)        \n",
    "\n",
    "        \n",
    "    def ShowResultsTable(self):\n",
    "        def _ui_show_result_table(sortcol1,sortcol2, sortorder1, sortorder2):\n",
    "            print(\"Selected columns and order: \", sortcol1,sortcol2, sortorder1, sortorder2)\n",
    "            allResults = self.allResults.reindex(\n",
    "                            index = self.dfBA.sort_values(by=[sortcol1,sortcol2], #['TP', 'BA'],#\n",
    "                                        ascending=[sortorder1,sortorder2]).index,\n",
    "                            copy=True)\n",
    "            pd.set_option(\"display.max_rows\", 400)\n",
    "            pd.set_option(\"display.max_columns\", 15)\n",
    "            pd.set_option(\"display.max_colwidth\", 2000)\n",
    "            display(allResults.loc[:, ~allResults.columns.isin(['res', 'model'])])\n",
    "            \n",
    "        sortableColumns = [item for item in list(self.allResults.columns) \n",
    "                   if item not in list(['vars', 'res', 'model'])] \n",
    "        self.dfBA = self.allResults.loc[:, sortableColumns].astype('float64').round(decimals=1)\n",
    "        sort1col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='BA',\n",
    "            description='Sort by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort2col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='passprob',\n",
    "            description='and by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort1order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=False,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "        sort2order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=True,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "\n",
    "        sort1ui = widgets.HBox([sort1col,sort1order])\n",
    "        sort2ui = widgets.HBox([sort2col,sort2order])\n",
    "        resultui = widgets.interactive_output(_ui_show_result_table,\n",
    "                            {'sortcol1':sort1col,'sortcol2':sort2col, \n",
    "                             'sortorder1':sort1order,'sortorder2':sort2order})\n",
    "        display(sort1ui,sort2ui,resultui)\n",
    "        \n",
    "    def getModelPrediction(self, modelNumber, dfInput):\n",
    "        modelresult = self.allResults.iloc[modelNumber].res\n",
    "        return modelresult.predict(dfInput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1 = LogisticRegression(df1, df2)  ## df1-big as train\n",
    "logreg3 = LogisticRegression(df3, df2)  ## df3-small as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e850e5b445d34511a4d91a2f1c8e25e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButton(value=False, description='Show models table', icon='check', layout=Layout(height='40px', width='aâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b054a350b8b8448c890e55e4fa3aadfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='3px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def out_show_models():\n",
    "    display(md(\"\"\"Models comparison table:\"\"\"))\n",
    "    logreg1.ShowResultsTable()\n",
    "    \n",
    "var = ShowHideableOutput(out_show_models, \"models table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "Based on made model, now user can input patient data and have predicted outcome for the illness. Form below accept all independent variebles, next they are passed to chosen outcome prediction model. Information from the form is gathered in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomePredictionUI: \n",
    "    def __init__(self, logReg, independentVars):\n",
    "        self.independentVars = independentVars.copy()\n",
    "        self.logReg = logReg\n",
    "        # self.formdf = pd.DataFrame(columns= [*self.independentVars, 'Result probability'])\n",
    "        self.formdf = self.logReg.dfTrain.drop(self.logReg.dfTrain.index)\n",
    "        self.i,self.j = 4,4\n",
    "        self.grid = widgets.GridspecLayout(self.i,self.j)\n",
    "        ### self.dfval = df[self.independentVars]\n",
    "        self.widgetsCreate()\n",
    "\n",
    "    def create_expanded_button(self,description, button_style):\n",
    "        return widgets.Button(description=description, button_style=button_style,\n",
    "                          layout=widgets.Layout(height='auto', width='auto'))\n",
    "\n",
    "    def widgetsCreate(self):\n",
    "        #BUTTONS\n",
    "        self.btn_Send = self.grid[2, 0] = self.create_expanded_button('Add to date frame'.format(0, 0), 'warning')\n",
    "        self.btn_Clear = self.grid[2, 1] = self.create_expanded_button('Clear'.format(0, 0), 'warning')\n",
    "        self.btn_Results = self.grid[2, 2] = self.create_expanded_button('Get results'.format(0, 0), 'warning')\n",
    "        #Fields to select\n",
    "        self.btn_sex = self.grid[0,0] = widgets.Dropdown(description='Sex', options =['Female','Male'])\n",
    "        self.btn_age = self.grid[0,1] = widgets.Dropdown(description='Age', options =range(26,100))\n",
    "        self.btn_episodes = self.grid[0,2] = widgets.Dropdown(description='Episodes number', options =range(1,5))\n",
    "        #Outcome\n",
    "        #self.btn_outcome = self.grid[1,0] = wdg.Text(value='.......', description='Outcome')\n",
    "        \n",
    "        # when button is clicked\n",
    "        for j in range(3):\n",
    "            self.grid[2,j].on_click(self.on_btn_click)\n",
    "        #display the grid and table\n",
    "        display(self.grid)\n",
    "\n",
    "    def addToDF(self):\n",
    "        \n",
    "        print('Age',self.btn_age.value,\n",
    "              ', Sex',self.btn_sex.value,\n",
    "              ', Episode Number',self.btn_episodes.value)\n",
    "        '''\n",
    "        if self.btn_sex.value == 'Female':\n",
    "            self.sex_value = 1\n",
    "        else:\n",
    "            self.sex_value = 0\n",
    "        '''\n",
    "        self.formdf = self.formdf.append(pd.DataFrame([[self.btn_age.value,self.btn_sex.value, \n",
    "                                           self.btn_episodes.value]], columns = self.independentVars),\n",
    "                                         ignore_index=True)\n",
    "        clear_output(wait=True)\n",
    "        self.widgetsCreate()\n",
    "        #display(self.formdf)\n",
    "        #return self.formdf\n",
    "        \n",
    "    def convertDF(self):\n",
    "        #for user convinence - select gender name\n",
    "        #later converting before prdictions\n",
    "        for i in range(0,len(self.formdf['sex_0male_1female'])):\n",
    "            self.formdf['sex_0male_1female'] =self.formdf['sex_0male_1female'].replace(['Male'],0)\n",
    "            self.formdf['sex_0male_1female'] =self.formdf['sex_0male_1female'].replace(['Female'],1)\n",
    "             \n",
    "    def clear(self):\n",
    "        clear_output(wait=True)\n",
    "        #self.formdf = pd.DataFrame(columns= self.independentVars)\n",
    "        self.formdf = self.logReg.dfTrain.drop(self.logReg.dfTrain.index)\n",
    "        self.widgetsCreate()\n",
    "\n",
    "    def on_btn_click(self, btn):\n",
    "        if btn.description == 'Add to date frame':\n",
    "            self.addToDF()\n",
    "        elif btn.description == 'Clear':\n",
    "            self.clear()\n",
    "        elif btn.description == 'Get results':\n",
    "            self.convertDF()\n",
    "            resProbs = self.logReg.getModelPrediction(140, self.formdf)\n",
    "            self.formdf['Result probability'] = resProbs\n",
    "        self.show_results()\n",
    "   \n",
    "    def show_results(self):\n",
    "        display(self.formdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad5fa1ed5144623a3edfd2f7f31067d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(Button(button_style='warning', description='Add to date frame', layout=Layout(grid_arâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.OutcomePredictionUI at 0x7fe6a412f0d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OutcomePredictionUI(logreg1, [\"age_years\", \"sex_0male_1female\", \"episode_number\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
