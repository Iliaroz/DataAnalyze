{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets\n",
    "#%pip install voila\n",
    "#%pip install voila-gridstack\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import pandas.util.testing as tm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import ipywidgets as wdg\n",
    "from IPython.display import display\n",
    "from ipywidgets import GridspecLayout\n",
    "import itertools\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input data\n",
    "## data filename\n",
    "datafilename1 = 'sepsis_survival_primary.csv'\n",
    "datafilename2 = 'sepsis_survival_study.csv'\n",
    "datafilename3 = 'sepsis_survival_validation.csv'\n",
    "\n",
    "## depended Variable column name\n",
    "dependVar = 'hospital_outcome_1alive_0dead'\n",
    "## exclude columns from analyze (text, urls, etc. )\n",
    "excludeColumns = []\n",
    "## minimum correlation coeff to assume as a key variable\n",
    "minimumCorrCoef = 0.01\n",
    "threshold = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_years</th>\n",
       "      <th>sex_0male_1female</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>hospital_outcome_1alive_0dead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_years  sex_0male_1female  episode_number  hospital_outcome_1alive_0dead\n",
       "0         21                  1               1                              1\n",
       "1         20                  1               1                              1\n",
       "2         21                  1               1                              1\n",
       "3         77                  0               1                              1\n",
       "4         72                  0               1                              1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read CSV file, autodetect delimeters, skip spaces in names\n",
    "df1 = pd.read_csv(datafilename1, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df2 = pd.read_csv(datafilename2, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df3 = pd.read_csv(datafilename3, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "dfs = [df1, df2, df3]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    ## exclude columns\n",
    "    df.drop(excludeColumns, axis ='columns', inplace = True)\n",
    "    ## and drop  all NaN\n",
    "    df.dropna(inplace=True)\n",
    "    ## place depended var into pos 0\n",
    "    poped = df.pop(dependVar)\n",
    "    df.insert(0, poped.name, poped)\n",
    "        \n",
    "## independed variable columns names  \n",
    "independVarList = list(df.columns.values)\n",
    "independVarList.remove(dependVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, dfTrain, dfTest):\n",
    "        self.dfTrain = dfTrain.copy()\n",
    "        self.dfTest = dfTest.copy()\n",
    "        self.models = []\n",
    "        self.modresults = []\n",
    "        self.predictVars = []\n",
    "        ### make models for all variables and combinations\n",
    "        self.allResults = pd.DataFrame(columns=['vars', 'passprob', 'res', 'model', 'BA', 'TP', 'FN', 'TN', 'FP'])\n",
    "        self.CalculateModels()\n",
    "        self.TestModels()\n",
    "        \n",
    "    def CalculateModels(self):\n",
    "        keyVars = self.GetKeyVariables(self.dfTrain)\n",
    "        self.dependVar = keyVars['key'].iloc[0]\n",
    "        ### All vars into list.\n",
    "        self.predictVars = keyVars['key'].iloc[1:].to_list()    ## .iloc[1:NvarsCount+1].to_list()\n",
    "        ### make models for all variables, sequently adding one by one\n",
    "        for n,indvar in enumerate(self.predictVars):\n",
    "            indvars = self.predictVars[:n+1]\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain)\n",
    "            res = model.fit(disp=False)\n",
    "            self.models.append(model)\n",
    "            self.modresults.append(res)\n",
    "\n",
    "\n",
    "    def GetKeyVariables(self, df):\n",
    "        parCorr = pd.DataFrame(df.corr() )\n",
    "        n = len(parCorr.columns)\n",
    "        keyVars = pd.DataFrame(columns=['key', 'val'])\n",
    "        ## depended variable moved to index 0\n",
    "        i = 0\n",
    "        for j in range( n):\n",
    "            if j >= i:\n",
    "                keyVars = keyVars.append({'key':parCorr.columns[j],'val':parCorr.iloc[i, j]}, ignore_index=True)\n",
    "        ## sort key vars by value\n",
    "        ##### keyVars.pop(df.columns[0])\n",
    "        keyVars.sort_values(by='val', key=abs, ascending=False, inplace=True)\n",
    "        return keyVars\n",
    "\n",
    "    \n",
    "    def get_BA(self, crossdf):\n",
    "        crossdf.index = crossdf.index.map(str)\n",
    "        crossdf.columns = crossdf.columns.map(str)\n",
    "        try: TN = crossdf.loc['0','0']\n",
    "        except: TN = 0\n",
    "        try: FN = crossdf.loc['0','1']\n",
    "        except: FN = 0\n",
    "        try: FP = crossdf.loc['1','0']\n",
    "        except: FP = 0\n",
    "        try: TP = crossdf.loc['1','1']\n",
    "        except: TP = 0\n",
    "        ###print('tn=', TN, 'fn=', FN, 'fp=', FP, 'tp=', TP)\n",
    "        # sensitivity = (TP)/(TP+FN)\n",
    "        # specificity = (TN)/(TN+FP)\n",
    "        # precision = (TP)/(TP+FP)\n",
    "        try: sensitivity = TP/(TP + FN)\n",
    "        except: sensitivity = np.NaN\n",
    "        try: specificity = TN/(TN + FP)\n",
    "        except: specificity = np.NaN\n",
    "        try: precision = TP/(TP + FP)\n",
    "        except: precision = np.NaN\n",
    "        BA = (sensitivity + specificity)/2\n",
    "        return dict(zip(['BA', 'sensitivity', 'specificity', 'precision', 'TN', 'FN', 'TP', 'FP'], [BA, sensitivity, specificity, precision, TN, FN, TP, FP]))\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def TestModels(self):\n",
    "        ### calculate BA for all threashholds...\n",
    "        passProbabilities = np.linspace(0,1,int(1/0.05)+1)\n",
    "\n",
    "        ## Generate all possible combinations of variables\n",
    "        variableList = sum([list(map(list, itertools.combinations(self.predictVars, i))) for i in range(len(self.predictVars) + 1)], [])\n",
    "        variableList = list(filter(None, variableList))\n",
    "\n",
    "        for n,indvars in enumerate(variableList):\n",
    "            ## progress # display(indvars)\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain )\n",
    "            fitresult = model.fit(disp=False)\n",
    "            for prob in passProbabilities:\n",
    "                inSample = pd.DataFrame({'probability':fitresult.predict(self.dfTest[indvars])}) \n",
    "                inSample['Model prediction'] = (inSample['probability'] >= prob).astype(int) ## 0 or 1 values based on probabilities\n",
    "                confMatrix = pd.crosstab(inSample['Model prediction'], self.dfTest[self.dependVar], dropna=False)\n",
    "                ba = self.get_BA(confMatrix)\n",
    "                ### add all info to one dataframe\n",
    "                ## TODO: memory consumption?\n",
    "                self.allResults = self.allResults.append({'vars':indvars, \n",
    "                                   'passprob':prob, \n",
    "                                   'res':fitresult, \n",
    "                                   'model':model, **(ba)},\n",
    "                                 ignore_index=True)        \n",
    "\n",
    "        \n",
    "    def ShowResultsTable(self):\n",
    "        def _ui_show_result_table(sortcol1,sortcol2, sortorder1, sortorder2):\n",
    "            print(\"Selected columns and order: \", sortcol1,sortcol2, sortorder1, sortorder2)\n",
    "            allResults = self.allResults.reindex(\n",
    "                            index = self.dfBA.sort_values(by=[sortcol1,sortcol2], #['TP', 'BA'],#\n",
    "                                        ascending=[sortorder1,sortorder2]).index,\n",
    "                            copy=True)\n",
    "            pd.set_option(\"display.max_rows\", 400)\n",
    "            pd.set_option(\"display.max_columns\", 10)\n",
    "            pd.set_option(\"display.max_colwidth\", 2000)\n",
    "            display(allResults.loc[:, ~allResults.columns.isin(['res', 'model'])])\n",
    "            \n",
    "        sortableColumns = [item for item in list(self.allResults.columns) \n",
    "                   if item not in list(['vars', 'res', 'model'])] \n",
    "        self.dfBA = self.allResults.loc[:, sortableColumns].astype('float64').round(decimals=1)\n",
    "        sort1col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='BA',\n",
    "            description='Sort by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort2col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='passprob',\n",
    "            description='and by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort1order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=False,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "        sort2order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=True,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "\n",
    "        sort1ui = widgets.HBox([sort1col,sort1order])\n",
    "        sort2ui = widgets.HBox([sort2col,sort2order])\n",
    "        resultui = widgets.interactive_output(_ui_show_result_table,\n",
    "                            {'sortcol1':sort1col,'sortcol2':sort2col, \n",
    "                             'sortorder1':sort1order,'sortorder2':sort2order})\n",
    "        display(sort1ui,sort2ui,resultui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf18bdc3451f440a99bcbbdd079e648e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectionSlider(continuous_update=False, description='Sort by...', index=1, options=('passprob'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66419931993474dac6cfe019152aaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectionSlider(continuous_update=False, description='and by...', options=('passprob', 'BA', 'T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c298841a0df54119ba4eaf29a1fac0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg1 = LogisticRegression(df1, df2)\n",
    "logreg1.ShowResultsTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfclean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m allVars\u001b[38;5;241m=\u001b[39m\u001b[43mdfclean\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m####WORK ON THIS ONE!!!!!\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m##PUT widgets horizontally\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nxdr \u001b[38;5;241m=\u001b[39m wdg\u001b[38;5;241m.\u001b[39mDropdown(options \u001b[38;5;241m=\u001b[39m allVars, value \u001b[38;5;241m=\u001b[39m allVars[\u001b[38;5;241m1\u001b[39m], \n\u001b[0;32m      5\u001b[0m                     description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX value\u001b[39m\u001b[38;5;124m'\u001b[39m, option \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX var\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfclean' is not defined"
     ]
    }
   ],
   "source": [
    "allVars=dfclean.columns\n",
    "####WORK ON THIS ONE!!!!!\n",
    "##PUT widgets horizontally\n",
    "nxdr = wdg.Dropdown(options = allVars, value = allVars[1], \n",
    "                    description = 'X value', option = 'X var')\n",
    "\n",
    "nBinsdr = wdg.Dropdown(options=[2,10,15,20,40], value=2, \n",
    "                    description = 'Bins number', option = 'Bin value')\n",
    "\n",
    "def plot_histogram(x = 'age_years', nBins = 15, PlotKDE = False):    \n",
    "    sns.histplot(data = dfclean[x] , bins = nBins, kde = PlotKDE)\n",
    "\n",
    "out = wdg.interact(plot_histogram, nBins = nBinsdr,PlotKDE = False,x=nxdr)\n",
    "ui = wdg.HBox([nxdr,nBinsdr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = dfclean.sample(frac=0.8, random_state = 200) #training data set (80%)\n",
    "dftest = dfclean.drop(dftrain.index) #testing data set (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allVars=dfclean.columns\n",
    "####WORK ON THIS ONE!!!!!\n",
    "##PUT widgets horizontally\n",
    "nxdr2x = wdg.Dropdown(options = allVars, value = allVars[1], \n",
    "                    description = 'X value', option = 'X var')\n",
    "nxdr2y = wdg.Dropdown(options = allVars, value = allVars[1], \n",
    "                    description = 'X value', option = 'X var')\n",
    "\n",
    "def plot_scatterplot(x = 'age_years', y = 'hospital_outcome_1alive_0dead'):    \n",
    "    sns.scatterplot(data = dfclean , x = x, y = y)\n",
    "\n",
    "out2 = wdg.interact(plot_scatterplot, x=nxdr2x, y = nxdr2y)\n",
    "ui = wdg.HBox([nxdr2x,nxdr2y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular regressional analise through all possible variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeatmapCorr(df): \n",
    "    sns.set(rc = {'figure.figsize':(15,8)})\n",
    "    sns.set_theme(style=\"white\")\n",
    "    corr = df.corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    # Custom colormap\n",
    "    cmap = sns.diverging_palette(275, 150, s=90, l=50, n=9, as_cmap=True)\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap,  linewidths=0.3, cbar_kws={\"shrink\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HeatmapCorr(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetKeyVariables(df):\n",
    "    parCorr = pd.DataFrame(df.corr() )\n",
    "    n = len(parCorr.columns)\n",
    "    keyVars = pd.DataFrame(columns=['key', 'val'])\n",
    "    ## depended variable moved to index 0\n",
    "    i = 0\n",
    "    for j in range( n):\n",
    "        if j >= i:\n",
    "            keyVars = keyVars.append({'key':parCorr.columns[j],'val':parCorr.iloc[i, j]}, ignore_index=True)\n",
    "    ## sort key vars by value\n",
    "    keyVars.pop(df.columns[0])\n",
    "    keyVars.sort_values(by='val', key=abs, ascending=False, inplace=True)\n",
    "    return keyVars\n",
    "\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set1]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set2]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set3]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set4]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set5]]))\n",
    "#display(GetKeyVariables(dftrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for1 = dftrain.columns[4]+'~'+dftrain.columns[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod = smf.ols(formula=for1, data = dftrain)\n",
    "#res = mod.fit()\n",
    "#res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LogRegModel(independVarList):\n",
    "    indepVars = ''\n",
    "    for i in range(0,len(independVarList)-1):\n",
    "        indepVars+=independVarList[i]\n",
    "        indepVars+=\" + \"\n",
    "    indepVars+=independVarList[-1]\n",
    "    depVar = dependVar\n",
    "    model = smf.logit(formula = depVar+' ~ '+ indepVars,data = dftrain)\n",
    "    res = model.fit()\n",
    "    print(depVar,'~',indepVars,':',\n",
    "              round(res.prsquared,5))#McFadden's pseudo-R-squared.\n",
    "    \"\"\"\n",
    "    inSample = pd.DataFrame({'prob':res.predict(dftest[independVarList])}) #probabilities \n",
    "    inSample['predLabel'] = (inSample['prob'] > threshold).astype(int) #labels based on probabilities\n",
    "    inSample.head()\n",
    "    confMatrix = pd.crosstab(inSample['predLabel'],dftest[depVar])\n",
    "    #sns.heatmap(confMatrix, annot = True)                  \n",
    "    #plt.show()\n",
    "    #calculation of BA \n",
    "    BA=0\n",
    "    TN = confMatrix.loc[0,0]\n",
    "    FN = confMatrix.loc[0,1]\n",
    "    FP = confMatrix.loc[1,0]\n",
    "    TP = confMatrix.loc[1,1]\n",
    "    TPR = TP/(TP + FN)\n",
    "    TNR = TN/(TN + FP)\n",
    "    BA = (TPR + TNR)/2\n",
    "    print(f'BA = {BA:0.4f}')\n",
    "    \"\"\"\n",
    "def LogRegModelSqrt(independVarList):\n",
    "    indepVars = ''\n",
    "    for i in range(0,len(independVarList)-1):\n",
    "        indepVars+='np.power('+independVarList[i]+',2)'\n",
    "        indepVars+=\" + \"\n",
    "    indepVars+='np.power('+independVarList[-1]+',2)'\n",
    "    depVar = dependVar\n",
    "    model = smf.logit(formula = depVar+' ~ '+ indepVars,data = dftrain)\n",
    "    res = model.fit()\n",
    "    print(depVar,'~',indepVars,':',\n",
    "              round(res.prsquared,5))#McFadden's pseudo-R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogRegModel(independVarList)\n",
    "#LogRegModel(independVarList[0:1])\n",
    "#LogRegModel(independVarList[1:2])\n",
    "#LogRegModel(independVarList[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogRegModelSqrt(independVarList)\n",
    "#LogRegModelSqrt(independVarList[0:1])\n",
    "#LogRegModelSqrt(independVarList[1:2])\n",
    "#LogRegModelSqrt(independVarList[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = (dftrain - dftrain.min())/(dftrain.max() - dftrain.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dftrain[[\"age_years\",\"sex_0male_1female\",\"episode_number\"]]\n",
    "y = dftrain[\"hospital_outcome_1alive_0dead\"]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def optimize(x, y,learning_rate,iterations,parameters): \n",
    "    size = x.shape[0]\n",
    "    weight = parameters[\"weight\"] \n",
    "    bias = parameters[\"bias\"]\n",
    "    for i in range(iterations): \n",
    "        sigma = sigmoid(np.dot(x, weight) + bias)\n",
    "        loss = -1/size * np.sum(y * np.log(sigma)) + (1 - y) * np.log(1 - sigma)\n",
    "        dW = 1/size * np.dot(x.T, (sigma - y)) \n",
    "        db = 1/size * np.sum(sigma - y)\n",
    "        weight -= learning_rate * dW\n",
    "        bias -= learning_rate * db \n",
    "    \n",
    "    parameters[\"weight\"] = weight\n",
    "    parameters[\"bias\"] = bias\n",
    "    return parameters\n",
    "# Initialize the weight and bias\n",
    "init_parameters = {} \n",
    "init_parameters[\"weight\"] = np.zeros(x.shape[1])\n",
    "init_parameters[\"bias\"] = 0\n",
    "\n",
    "def train(x, y, learning_rate,iterations):\n",
    "    parameters_out = optimize(x, y, learning_rate, iterations ,init_parameters)\n",
    "    return parameters_out\n",
    "# Train the model\n",
    "parameters_out = train(x, y, learning_rate = 0.02, iterations = 500)\n",
    "parameters_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "#print(len(df3))\n",
    "df3_scaled = (df3 - dftrain.min())/(dftrain.max() - dftrain.min())\n",
    " #- df3.min())/(df3.max() - df3.min())\n",
    "x = df3_scaled[[\"age_years\",\"sex_0male_1female\",\"episode_number\"]]\n",
    "y = df3_scaled[\"hospital_outcome_1alive_0dead\"]\n",
    "output_vals = np.dot(x,parameters_out[\"weight\"]) + parameters_out[\"bias\"]\n",
    "predictions = sigmoid(output_vals) >= 1/2\n",
    "#print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(df['hospital_outcome_1alive_0dead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countT=0\n",
    "countF=0\n",
    "for i in np.array(predictions==np.array(df3_scaled['hospital_outcome_1alive_0dead'])):\n",
    "    if i ==True:\n",
    "        countT += 1\n",
    "    elif i== False: \n",
    "        countF +=1\n",
    "print(countF,countT, \"Prediction accuracy:\", countT/(countT+countF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j = 4,4\n",
    "grid = GridspecLayout(i,j)\n",
    "dfval = dftrain[[\"age_years\",\"sex_0male_1female\",\"episode_number\"]] \n",
    "#print(dfval.min())\n",
    "def create_expanded_button(description, button_style):\n",
    "    return wdg.Button(description=description, button_style=button_style,\n",
    "                      layout=wdg.Layout(height='auto', width='auto'))\n",
    "\n",
    "\n",
    "grid[2, 0] = create_expanded_button('Send'.format(0, 0), 'warning')\n",
    "grid[2, 1] = create_expanded_button('Clear'.format(0, 0), 'warning')\n",
    "btn_sex = grid[0,0] = wdg.Dropdown(description='Sex', options =['Female','Male'])\n",
    "btn_age = grid[0,1] = wdg.Dropdown(description='Age', options =range(26,100))\n",
    "btn_episodes = grid[0,2] = wdg.Dropdown(description='Episodes number', options =range(1,5))\n",
    "\n",
    "btn_outcome = grid[1,0] = wdg.Text(value='.......', description='Outcome')\n",
    "\n",
    "def evaluate():\n",
    "    Alist = 0\n",
    "    print('Sex:',btn_sex.value,\n",
    "          ', Age:',btn_age.value,\n",
    "          ', Episode Number',btn_episodes.value)\n",
    "    sex_value = 1\n",
    "    if btn_sex.value == 'Female':\n",
    "        sex_value = 1\n",
    "    else:\n",
    "        sex_value = 0\n",
    "    \n",
    "    Alist = np.array([btn_age.value,sex_value,btn_episodes.value])\n",
    "    print(Alist)\n",
    "  \n",
    "    Alist_scaled = (Alist - dfval.min())/(dfval.max() - dfval.min())   \n",
    "    print(Alist_scaled)\n",
    "    x = Alist_scaled\n",
    "    output_vals = np.dot(x,parameters_out[\"weight\"]) + parameters_out[\"bias\"]\n",
    "    predictions = sigmoid(output_vals) >= 1/2\n",
    "    if predictions == True:\n",
    "         btn_outcome.value = 'ALIVE'\n",
    "    elif predictions ==False:\n",
    "        btn_outcome.value = 'DEAD'\n",
    "    \n",
    "def clear():\n",
    "    print('clear')\n",
    "        \n",
    "\n",
    "def on_btn_click(btn):\n",
    "    if btn.description == 'Send':\n",
    "        evaluate()\n",
    "    elif btn.description == 'Clear':\n",
    "        clear()\n",
    "\n",
    "for j in range(2):\n",
    "    grid[2,j].on_click(on_btn_click)\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
