{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets\n",
    "#%pip install voila\n",
    "#%pip install voila-gridstack\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import pandas.util.testing as tm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import ipywidgets as wdg\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import GridspecLayout\n",
    "import itertools\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input data\n",
    "## data filename\n",
    "datafilename1 = 'sepsis_survival_primary.csv'\n",
    "datafilename2 = 'sepsis_survival_study.csv'\n",
    "datafilename3 = 'sepsis_survival_validation.csv'\n",
    "\n",
    "## depended Variable column name\n",
    "dependVar = 'hospital_outcome_1alive_0dead'\n",
    "## exclude columns from analyze (text, urls, etc. )\n",
    "excludeColumns = []\n",
    "## minimum correlation coeff to assume as a key variable\n",
    "minimumCorrCoef = 0.01\n",
    "threshold = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read CSV file, autodetect delimeters, skip spaces in names\n",
    "df1 = pd.read_csv(datafilename1, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df2 = pd.read_csv(datafilename2, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "df3 = pd.read_csv(datafilename3, sep=None, engine=\"python\", skipinitialspace=True)\n",
    "dfs = [df1, df2, df3]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    ## exclude columns\n",
    "    df.drop(excludeColumns, axis ='columns', inplace = True)\n",
    "    ## and drop  all NaN\n",
    "    df.dropna(inplace=True)\n",
    "    ## place depended var into pos 0\n",
    "    poped = df.pop(dependVar)\n",
    "    df.insert(0, poped.name, poped)\n",
    "        \n",
    "## independed variable columns names  \n",
    "independVarList = list(df.columns.values)\n",
    "independVarList.remove(dependVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, dfTrain, dfTest):\n",
    "        self.dfTrain = dfTrain.copy()\n",
    "        self.dfTest = dfTest.copy()\n",
    "        self.models = []\n",
    "        self.modresults = []\n",
    "        self.predictVars = []\n",
    "        ### make models for all variables and combinations\n",
    "        self.allResults = pd.DataFrame(columns=['vars', 'passprob', 'res', 'model', 'BA', 'TP', 'FN', 'TN', 'FP'])\n",
    "        self.CalculateModels()\n",
    "        self.TestModels()\n",
    "        \n",
    "    def CalculateModels(self):\n",
    "        keyVars = self.GetKeyVariables(self.dfTrain)\n",
    "        self.dependVar = keyVars['key'].iloc[0]\n",
    "        ### All vars into list.\n",
    "        self.predictVars = keyVars['key'].iloc[1:].to_list()    ## .iloc[1:NvarsCount+1].to_list()\n",
    "        ### make models for all variables, sequently adding one by one\n",
    "        for n,indvar in enumerate(self.predictVars):\n",
    "            indvars = self.predictVars[:n+1]\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain)\n",
    "            res = model.fit(disp=False)\n",
    "            self.models.append(model)\n",
    "            self.modresults.append(res)\n",
    "\n",
    "\n",
    "    def GetKeyVariables(self, df):\n",
    "        parCorr = pd.DataFrame(df.corr() )\n",
    "        n = len(parCorr.columns)\n",
    "        keyVars = pd.DataFrame(columns=['key', 'val'])\n",
    "        ## depended variable moved to index 0\n",
    "        i = 0\n",
    "        for j in range( n):\n",
    "            if j >= i:\n",
    "                keyVars = keyVars.append({'key':parCorr.columns[j],'val':parCorr.iloc[i, j]}, ignore_index=True)\n",
    "        ## sort key vars by value\n",
    "        ##### keyVars.pop(df.columns[0])\n",
    "        keyVars.sort_values(by='val', key=abs, ascending=False, inplace=True)\n",
    "        return keyVars\n",
    "\n",
    "    \n",
    "    def get_BA(self, crossdf):\n",
    "        crossdf.index = crossdf.index.map(str)\n",
    "        crossdf.columns = crossdf.columns.map(str)\n",
    "        try: TN = crossdf.loc['0','0']\n",
    "        except: TN = 0\n",
    "        try: FN = crossdf.loc['0','1']\n",
    "        except: FN = 0\n",
    "        try: FP = crossdf.loc['1','0']\n",
    "        except: FP = 0\n",
    "        try: TP = crossdf.loc['1','1']\n",
    "        except: TP = 0\n",
    "        ###print('tn=', TN, 'fn=', FN, 'fp=', FP, 'tp=', TP)\n",
    "        try: TPR = TP/(TP + FN)\n",
    "        except: TPR = np.NaN\n",
    "        try: TNR = TN/(TN + FP)\n",
    "        except: TNR = np.NaN\n",
    "        BA = (TPR + TNR)/2\n",
    "        return dict(zip(['BA', 'TN', 'FN', 'TP', 'FP'], [BA, TN, FN, TP, FP]))\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def TestModels(self):\n",
    "        ### calculate BA for all threashholds...\n",
    "        passProbabilities = np.linspace(0,1,int(1/0.05)+1)\n",
    "\n",
    "        ## Generate all possible combinations of variables\n",
    "        variableList = sum([list(map(list, itertools.combinations(self.predictVars, i))) for i in range(len(self.predictVars) + 1)], [])\n",
    "        variableList = list(filter(None, variableList))\n",
    "\n",
    "        for n,indvars in enumerate(variableList):\n",
    "            ## progress # display(indvars)\n",
    "            modvars = list(map(lambda orig_string: 'Q(\"' + orig_string + '\")', indvars))\n",
    "            model = smf.logit(formula = '' + dependVar + ' ~ ' + ' + '.join(modvars), data = self.dfTrain )\n",
    "            fitresult = model.fit(disp=False)\n",
    "            for prob in passProbabilities:\n",
    "                inSample = pd.DataFrame({'probability':fitresult.predict(self.dfTest[indvars])}) \n",
    "                inSample['Model prediction'] = (inSample['probability'] >= prob).astype(int) ## 0 or 1 values based on probabilities\n",
    "                confMatrix = pd.crosstab(inSample['Model prediction'], self.dfTest[self.dependVar], dropna=False)\n",
    "                ba = self.get_BA(confMatrix)\n",
    "                ### add all info to one dataframe\n",
    "                ## TODO: memory consumption?\n",
    "                self.allResults = self.allResults.append({'vars':indvars, \n",
    "                                   'passprob':prob, \n",
    "                                   'res':fitresult, \n",
    "                                   'model':model,\n",
    "                                   'R':fitresult.prsquared,\n",
    "                                                          **(ba)},\n",
    "                                 ignore_index=True)        \n",
    "\n",
    "        \n",
    "    def ShowResultsTable(self):\n",
    "        def _ui_show_result_table(sortcol1,sortcol2, sortorder1, sortorder2):\n",
    "            print(\"Selected columns and order: \", sortcol1,sortcol2, sortorder1, sortorder2)\n",
    "            allResults = self.allResults.reindex(\n",
    "                            index = self.dfBA.sort_values(by=[sortcol1,sortcol2], #['TP', 'BA'],#\n",
    "                                        ascending=[sortorder1,sortorder2]).index,\n",
    "                            copy=True)\n",
    "            pd.set_option(\"display.max_rows\", 400)\n",
    "            pd.set_option(\"display.max_columns\", 10)\n",
    "            pd.set_option(\"display.max_colwidth\", 2000)\n",
    "            display(allResults.loc[:, ~allResults.columns.isin(['res', 'model'])])\n",
    "            \n",
    "        sortableColumns = [item for item in list(self.allResults.columns) \n",
    "                   if item not in list(['vars', 'res', 'model'])] \n",
    "        self.dfBA = self.allResults.loc[:, sortableColumns].astype('float64').round(decimals=2)\n",
    "        sort1col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='BA',\n",
    "            description='Sort by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort2col = widgets.SelectionSlider(\n",
    "            options=sortableColumns,\n",
    "            value='passprob',\n",
    "            description='and by...',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True\n",
    "        )\n",
    "        sort1order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=False,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "        sort2order = widgets.ToggleButtons(\n",
    "            options=[('Ascending',True), ('Descending',False)],\n",
    "            value=True,\n",
    "            description='Order:',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltips=['Sort column in ascending order (1..99)', 'Sort column in descending order (99..1)']\n",
    "        )\n",
    "\n",
    "        sort1ui = widgets.HBox([sort1col,sort1order])\n",
    "        sort2ui = widgets.HBox([sort2col,sort2order])\n",
    "        resultui = widgets.interactive_output(_ui_show_result_table,\n",
    "                            {'sortcol1':sort1col,'sortcol2':sort2col, \n",
    "                             'sortorder1':sort1order,'sortorder2':sort2order})\n",
    "        display(sort1ui,sort2ui,resultui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg1 = LogisticRegression(df1, df2)  ## df1-big as train\n",
    "logreg3 = LogisticRegression(df3, df2)  ## df3-small as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui_compare = widgets.HBox(logreg1.ShowResultsTable(), logreg3.ShowResultsTable())\n",
    "display(ui_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogramPlot(df):    \n",
    "    allVars=df.columns\n",
    "    nxdr = wdg.Dropdown(options = allVars, value = allVars[1], \n",
    "                        description = 'X value', option = 'X var')\n",
    "\n",
    "    nBinsdr = wdg.Dropdown(options=[2,10,15,20,40], value=2, \n",
    "                        description = 'Bins number', option = 'Bin value')\n",
    "\n",
    "    def plot_histogram(x = 'age_years', nBins = 15, PlotKDE = False):    \n",
    "        sns.histplot(data = df[x] , bins = nBins, kde = PlotKDE)\n",
    "\n",
    "    out = wdg.interact(plot_histogram, nBins = nBinsdr,PlotKDE = False,x=nxdr)\n",
    "    ui = wdg.HBox([nxdr,nBinsdr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterPlot(df):\n",
    "    allVars=df.columns\n",
    "    nxdr2x = wdg.Dropdown(options = allVars, value = allVars[1], \n",
    "                        description = 'X value', option = 'X var')\n",
    "    nxdr2y = wdg.Dropdown(options = allVars, value = allVars[1], \n",
    "                        description = 'X value', option = 'X var')\n",
    "\n",
    "    def plot_scatterplot(x = 'age_years', y = 'hospital_outcome_1alive_0dead'):    \n",
    "        sns.scatterplot(data = df, x = x, y = y)\n",
    "\n",
    "    out2 = wdg.interact(plot_scatterplot, x=nxdr2x, y = nxdr2y)\n",
    "    ui = wdg.HBox([nxdr2x,nxdr2y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterPlot(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular regressional analise through all possible variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeatmapCorr(df): \n",
    "    sns.set(rc = {'figure.figsize':(15,8)})\n",
    "    sns.set_theme(style=\"white\")\n",
    "    corr = df.corr()\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "    # Custom colormap\n",
    "    cmap = sns.diverging_palette(275, 150, s=90, l=50, n=9, as_cmap=True)\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap,  linewidths=0.3, cbar_kws={\"shrink\":0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#HeatmapCorr(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutcomePredictionUI: \n",
    "    def __init__(self, df,independentVars):\n",
    "        self.df = df.copy()\n",
    "        self.independentVars = independentVars.copy()\n",
    "        self.formdf = pd.DataFrame(columns= self.independentVars)\n",
    "        self.i,self.j = 4,4\n",
    "        self.grid = GridspecLayout(self.i,self.j)\n",
    "        self.dfval = df[self.independentVars]\n",
    "        self.widgetsCreate()\n",
    "\n",
    "    def create_expanded_button(self,description, button_style):\n",
    "        return wdg.Button(description=description, button_style=button_style,\n",
    "                          layout=wdg.Layout(height='auto', width='auto'))\n",
    "\n",
    "    def widgetsCreate(self):\n",
    "        #BUTTONS\n",
    "        self.btn_Send = self.grid[2, 0] = self.create_expanded_button('Add to date frame'.format(0, 0), 'warning')\n",
    "        self.btn_Clear = self.grid[2, 1] = self.create_expanded_button('Clear'.format(0, 0), 'warning')\n",
    "        #Fields to select\n",
    "        self.btn_sex = self.grid[0,0] = wdg.Dropdown(description='Sex', options =['Female','Male'])\n",
    "        self.btn_age = self.grid[0,1] = wdg.Dropdown(description='Age', options =range(26,100))\n",
    "        self.btn_episodes = self.grid[0,2] = wdg.Dropdown(description='Episodes number', options =range(1,5))\n",
    "        #Outcome\n",
    "        #self.btn_outcome = self.grid[1,0] = wdg.Text(value='.......', description='Outcome')\n",
    "        # when button is clicked\n",
    "        for j in range(2):\n",
    "            self.grid[2,j].on_click(self.on_btn_click)\n",
    "        #display the grid\n",
    "        display(self.grid)\n",
    "\n",
    "    def addToDF(self):\n",
    "        \n",
    "        print('Sex:',self.btn_sex.value,\n",
    "              ', Age:',self.btn_age.value,\n",
    "              ', Episode Number',self.btn_episodes.value)\n",
    "        \n",
    "        #sex_value = 1\n",
    "        if self.btn_sex.value == 'Female':\n",
    "            self.sex_value = 1\n",
    "        else:\n",
    "            self.sex_value = 0\n",
    "        \n",
    "        self.formdf = self.formdf.append(pd.DataFrame([[self.btn_sex.value,self.btn_age.value, \n",
    "                                           self.btn_episodes.value]], columns = self.independentVars),\n",
    "                                         ignore_index=True)\n",
    "        clear_output(wait=True)\n",
    "        self.widgetsCreate()\n",
    "        display(self.formdf)\n",
    "        return self.formdf\n",
    "        \n",
    "    def clear(self):\n",
    "        clear_output(wait=True)\n",
    "        self.formdf = pd.DataFrame(columns= self.independentVars)\n",
    "        self.widgetsCreate()\n",
    "\n",
    "    def on_btn_click(self, btn):\n",
    "        if btn.description == 'Add to date frame':\n",
    "            self.addToDF()\n",
    "        elif btn.description == 'Clear':\n",
    "            self.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutcomePredictionUI(df1, [\"age_years\", \"sex_0male_1female\", \"episode_number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \"\"\"\n",
    "        Alist = np.array([btn_age.value,sex_value,btn_episodes.value])\n",
    "        print(Alist)\n",
    "\n",
    "        Alist_scaled = (Alist - dfval.min())/(dfval.max() - dfval.min())   \n",
    "        print(Alist_scaled)\n",
    "        x = Alist_scaled\n",
    "        output_vals = np.dot(x,parameters_out[\"weight\"]) + parameters_out[\"bias\"]\n",
    "        predictions = sigmoid(output_vals) >= 1/2\n",
    "        if predictions == True:\n",
    "             btn_outcome.value = 'ALIVE'\n",
    "        elif predictions ==False:\n",
    "            btn_outcome.value = 'DEAD'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetKeyVariables(df):\n",
    "    parCorr = pd.DataFrame(df.corr() )\n",
    "    n = len(parCorr.columns)\n",
    "    keyVars = pd.DataFrame(columns=['key', 'val'])\n",
    "    ## depended variable moved to index 0\n",
    "    i = 0\n",
    "    for j in range( n):\n",
    "        if j >= i:\n",
    "            keyVars = keyVars.append({'key':parCorr.columns[j],'val':parCorr.iloc[i, j]}, ignore_index=True)\n",
    "    ## sort key vars by value\n",
    "    keyVars.pop(df.columns[0])\n",
    "    keyVars.sort_values(by='val', key=abs, ascending=False, inplace=True)\n",
    "    return keyVars\n",
    "\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set1]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set2]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set3]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set4]]))\n",
    "#display(GetKeyVariables(dftrain[[dependVar, *set5]]))\n",
    "#display(GetKeyVariables(dftrain))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
